{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af6d7eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shenyu/miniconda3/envs/sean/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/shenyu/miniconda3/envs/sean/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c107WarningC1ENS_7variantIJNS0_11UserWarningENS0_18DeprecationWarningEEEERKNS_14SourceLocationENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "###### data loader####\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as tfms\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import open_clip\n",
    "from open_clip import create_model_from_pretrained, get_tokenizer # works on open-clip-torch>=2.23.0, timm>=0.9.8\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os.path as osp\n",
    "\n",
    "torch.set_num_threads(5)   # Sets the number of threads used for intra-operations\n",
    "torch.set_num_interop_threads(5)   # Sets the number of threads used for inter-operations\n",
    "\n",
    "import open_clip\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "logabs = lambda x: torch.log(torch.abs(x))\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Changes the seed for reproducibility. \n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "\n",
    "model, preprocess = create_model_from_pretrained('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "tokenizer = get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "\n",
    "\n",
    "seed_everything(1024)\n",
    "\n",
    "\n",
    "\n",
    "def get_transform():\n",
    "    transform = tfms.Compose([\n",
    "        tfms.Resize((224,224)),\n",
    "        tfms.ToTensor()\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "class ConfounderDataset(Dataset):\n",
    "    def __init__(self, root_dir,\n",
    "                 target_name, confounder_names,\n",
    "                 model_type=None, augment_data=None):\n",
    "        \n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.split == 'train':\n",
    "            return len(self.training_sample)\n",
    "        if self.split == 'val':\n",
    "            return len(self.valid_sample)\n",
    "        if self.split == 'test':\n",
    "            return len(self.test_sample)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.split == 'train': \n",
    "            y = self.training_sample_y_array[idx]\n",
    "            y = torch.tensor(y)\n",
    "            a = self.training_sample_confounder_array[idx]\n",
    "            a = torch.tensor(a)\n",
    "            img_filename = os.path.join(\n",
    "                self.data_dir,\n",
    "                self.training_sample[idx]) \n",
    "            img = Image.open(img_filename).convert('RGB')\n",
    "\n",
    "            x = preprocess(img)\n",
    "            img_for_res = self.transform(img)\n",
    "            \n",
    "            \n",
    "        if self.split == 'val': \n",
    "            y = self.valid_sample_y_array[idx]\n",
    "            y = torch.tensor(y)\n",
    "            a = self.valid_sample_confounder_array[idx]\n",
    "            a = torch.tensor(a)\n",
    "            img_filename = os.path.join(\n",
    "                self.data_dir,\n",
    "                self.valid_sample[idx])       \n",
    "            img = Image.open(img_filename).convert('RGB')\n",
    "\n",
    "            x = preprocess(img)\n",
    "            img_for_res = self.transform(img)\n",
    "            \n",
    "        if self.split == 'test': \n",
    "            y = self.test_sample_y_array[idx]\n",
    "            a = self.test_sample_confounder_array[idx]\n",
    "            y = torch.tensor(y)\n",
    "            a = torch.tensor(a)\n",
    "            img_filename = os.path.join(\n",
    "                self.data_dir,\n",
    "                self.test_sample[idx])       \n",
    "            img = Image.open(img_filename).convert('RGB')\n",
    "\n",
    "            x = preprocess(img)\n",
    "            img_for_res = self.transform(img)\n",
    "        return x,y,a, img_for_res\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class ISICDataset(ConfounderDataset):\n",
    "    def __init__(self, \n",
    "                 root_dir,\n",
    "                 seed,\n",
    "                 split,\n",
    "                 target_name = ['label'], \n",
    "                 confounder_names=['patches'],\n",
    "                 model_type=None,\n",
    "                 augment_data=False,\n",
    "                 mix_up=False,\n",
    "                 group_id=None,\n",
    "                 id_val=True):\n",
    "        self.split = split\n",
    "        self.augment_data = augment_data\n",
    "        self.group_id = group_id\n",
    "        self.mix_up = mix_up\n",
    "        self.model_type = model_type\n",
    "        self.target_name = target_name\n",
    "        self.confounder_names = confounder_names\n",
    "        self.split_dir = osp.join(root_dir, 'trap-sets')\n",
    "        self.data_dir = osp.join(root_dir, 'ISIC2018_Task1-2_Training_Input')\n",
    "        \n",
    "        metadata = {}\n",
    "        metadata['train'] = pd.read_csv(osp.join(self.split_dir, f'isic_annotated_train{seed}.csv'))\n",
    "        if id_val:\n",
    "            test_val_data = pd.read_csv(osp.join(self.split_dir, f'isic_annotated_test{seed}.csv'))\n",
    "            idx_val, idx_test = train_test_split(np.arange(len(test_val_data)), \n",
    "                                                test_size=0.8, random_state=0)\n",
    "            metadata['test'] = test_val_data.iloc[idx_test]\n",
    "            metadata['val'] = test_val_data.iloc[idx_val]\n",
    "        else:\n",
    "            metadata['test'] = pd.read_csv(osp.join(self.split_dir, f'isic_annotated_test{seed}.csv'))\n",
    "            metadata['val'] = pd.read_csv(osp.join(self.split_dir, f'isic_annotated_val{seed}.csv'))\n",
    "            metadata_new = metadata['train'].merge(metadata['val'], how='left', indicator=True)\n",
    "            metadata_new = metadata_new[metadata_new['_merge'] == 'left_only']\n",
    "            metadata['train'] = metadata_new.drop(columns=['_merge'])\n",
    "        \n",
    "        \n",
    "        self.precomputed = False\n",
    "        self.pretransformed = False\n",
    "        self.n_classes = 2\n",
    "        self.n_confounders = 1\n",
    "        confounder = confounder_names[0]\n",
    "        \n",
    "        self.training_sample = metadata['train']['image'].values\n",
    "        self.training_sample_y_array = metadata['train'][target_name].values\n",
    "        self.training_sample_confounder_array = metadata['train'][confounder].values\n",
    "        \n",
    "        self.valid_sample = metadata['val']['image'].values\n",
    "        self.valid_sample_y_array = metadata['val'][target_name].values\n",
    "        self.valid_sample_confounder_array = metadata['val'][confounder].values\n",
    "        \n",
    "        self.test_sample = metadata['test']['image'].values\n",
    "        self.test_sample_y_array = metadata['test'][target_name].values\n",
    "        self.test_sample_confounder_array = metadata['test'][confounder].values\n",
    "        self.transform = get_transform()\n",
    "        \n",
    "\n",
    "    \n",
    "data_dir = r\"../isic\"\n",
    "seed = 1\n",
    "\n",
    "training_isic_dataset  = ISICDataset(data_dir, seed, 'train')\n",
    "valid_isic_dataset  = ISICDataset(data_dir, seed, 'val')\n",
    "test_isic_dataset  = ISICDataset(data_dir, seed, 'test')\n",
    "\n",
    "\n",
    "training_data_loader  = torch.utils.data.DataLoader(dataset = training_isic_dataset,\n",
    "                                                batch_size= batch_size,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0)\n",
    "\n",
    "valid_data_loader  = torch.utils.data.DataLoader(dataset = valid_isic_dataset,\n",
    "                                                batch_size= batch_size,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=0)\n",
    "\n",
    "test_data_loader  = torch.utils.data.DataLoader(dataset = test_isic_dataset,\n",
    "                                                batch_size= batch_size,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=0)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c46aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "spurious_text = [\"There exists a color patch\",  \"There exists no color patch\"] \n",
    "texts = tokenizer(spurious_text).to(device)\n",
    "null_image = torch.rand((1,3,224,224)).to(device)\n",
    "model = model.to(device)\n",
    "_, spurious_embedding, _ = model(null_image, texts)\n",
    "\n",
    "no_patch = spurious_embedding[1].unsqueeze(0).to(device)\n",
    "patch = spurious_embedding[0].unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a11eb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Scale: 100%|███████████████████████████████████████████████████████████████████████████| 8/8 [06:24<00:00, 48.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30454728\n",
      "0.29942143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero Shot Testing: 100%|█████████████████████████████████████████████████████████████████████████| 3/3 [02:07<00:00, 42.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for y=0, s=0: 0.6910755148741419\n",
      "Accuracy for y=0, s=1: 0.8545454545454545\n",
      "Accuracy for y=1, s=0: 0.6587301587301587\n",
      "acc 0.6990291262135923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def inference_a_test(vlm, spu_v0, spu_v1):\n",
    "    correct_00, total_00 = 0, 0\n",
    "    correct_01, total_01 = 0, 0\n",
    "    correct_10, total_10 = 0, 0\n",
    "    correct_11, total_11 = 0, 0\n",
    "    \n",
    "    for step, (test_input, test_target, sensitive, _) in enumerate(tqdm(test_data_loader, desc=\"Testing\")):\n",
    "        with torch.no_grad():\n",
    "            test_target = test_target.to(device)\n",
    "            sensitive = sensitive.to(device)\n",
    "            test_target = test_target.squeeze()\n",
    "            test_input = test_input.to(device)\n",
    "            z = vlm.encode_image(test_input)\n",
    "            infered_a = inference_a(vlm, no_patch, patch,z )\n",
    "            \n",
    "            mask_00 = ((test_target == 0) & (sensitive == 0))\n",
    "            mask_01 = ((test_target == 0) & (sensitive == 1))\n",
    "            mask_10 = ((test_target == 1) & (sensitive == 0))\n",
    "            mask_11 = ((test_target == 1) & (sensitive == 1))\n",
    "\n",
    "            correct_00 += (infered_a[mask_00] == sensitive[mask_00]).float().sum().item()\n",
    "            total_00 += mask_00.float().sum().item()\n",
    "\n",
    "            correct_01 += (infered_a[mask_01] == sensitive[mask_01]).float().sum().item()\n",
    "            total_01 += mask_01.float().sum().item()\n",
    "\n",
    "            correct_10 += (infered_a[mask_10] == sensitive[mask_10]).float().sum().item()\n",
    "            total_10 += mask_10.float().sum().item()\n",
    "\n",
    "            correct_11 += (infered_a[mask_11] == sensitive[mask_11]).float().sum().item()\n",
    "            total_11 += mask_11.float().sum().item() \n",
    "    acc_00 = correct_00 / total_00\n",
    "    acc_01 = correct_01 / total_01\n",
    "    acc_10 = correct_10 / total_10\n",
    "    acc_11 = correct_11 / (total_11+1e-9)\n",
    "\n",
    "    print(f'Accuracy for y=0, s=0: {acc_00}')\n",
    "    print(f'Accuracy for y=0, s=1: {acc_01}')\n",
    "    print(f'Accuracy for y=1, s=0: {acc_10}')\n",
    "    print(f'Accuracy for y=1, s=1: {acc_11}')   \n",
    "\n",
    "            \n",
    "def inference_a(vlm, spu_v0, spu_v1, z):\n",
    "    text_embeddings = torch.cat((spu_v0, spu_v1), dim=0)\n",
    "    norm_img_embeddings = z \n",
    "    norm_text_embeddings = text_embeddings / text_embeddings.norm(dim=1, keepdim=True)\n",
    "    cosine_similarity = torch.mm(norm_img_embeddings, norm_text_embeddings.t())\n",
    "    logits_per_image = cosine_similarity \n",
    "    probs = logits_per_image.softmax(dim=1)\n",
    "    _, predic = torch.max(probs.data, 1)\n",
    "    return predic\n",
    "\n",
    "            \n",
    "def supervised_inference_a(img):\n",
    "    resnet18 = models.resnet18(pretrained=False)\n",
    "    num_classes = 2 \n",
    "    resnet18.fc = nn.Linear(resnet18.fc.in_features, num_classes)\n",
    "    res_model = resnet18\n",
    "    res_model.load_state_dict(torch.load('res_net.pth'))\n",
    "    res_model = res_model.to(device)\n",
    "    res_model.eval()\n",
    "    img = img.to(device)\n",
    "    test_pred_ = res_model(img)\n",
    "    _, predic = torch.max(test_pred_.data, 1)\n",
    "    return predic            \n",
    "            \n",
    "    \n",
    "def compute_scale(vlm, spu_v0, spu_v1):\n",
    "    vlm = vlm.to(device)\n",
    "    scale_0 = []\n",
    "    scale_1 = []\n",
    "    spu0 = spu_v0  / spu_v0.norm(dim=1, keepdim=True)\n",
    "    spu1 = spu_v1 / spu_v1.norm(dim=1, keepdim=True)\n",
    "\n",
    "    \n",
    "    for step, (test_input, _, sensitive, img) in enumerate(tqdm(training_data_loader, desc=\"Computing Scale\")):\n",
    "        with torch.no_grad():\n",
    "            test_input = test_input.to(device)\n",
    "            z = vlm.encode_image(test_input)\n",
    "            if a ==True:\n",
    "                sensitive = sensitive\n",
    "            else:\n",
    "                if partial_a == False:\n",
    "                    sensitive = inference_a(vlm, no_patch, patch,z )\n",
    "                elif partial_a == True:\n",
    "                    sensitive = supervised_inference_a(img)\n",
    "            \n",
    "            \n",
    "            mask_0 = sensitive == 0\n",
    "            mask_0 = mask_0.to(device)\n",
    "            h = z[mask_0]\n",
    "            inner_no_patch = torch.mm(h/ h.norm(dim=1, keepdim=True), spu0.t())\n",
    "            scale_0.extend(inner_no_patch.detach().cpu().numpy())\n",
    "                \n",
    "            mask_1 = sensitive == 1\n",
    "            mask_1 = mask_1.to(device)\n",
    "            g = z[mask_1]\n",
    "            inner_patch = torch.mm(g/ g.norm(dim=1, keepdim=True), spu1.t())\n",
    "            scale_1.extend(inner_patch.detach().cpu().numpy())\n",
    "    scale_0 = np.array(scale_0)\n",
    "    scale_1 = np.array(scale_1)\n",
    "    print(np.mean(scale_0))\n",
    "    print(np.mean(scale_1))\n",
    "    return torch.tensor(np.mean(scale_0)), torch.tensor(np.mean(scale_1))\n",
    "\n",
    "\n",
    "\n",
    "def test_epoch(vlm,   dataloader):\n",
    "    scale_0, scale_1 = compute_scale(model, no_patch, patch)\n",
    "\n",
    "    texts_label = [\"This is a benign lesion\",  \"This is a malignant lesion\"] \n",
    "    text_label_tokened = tokenizer(texts_label).to(device)\n",
    "    \n",
    "    vlm = vlm.to(device)\n",
    "    vlm.eval()   \n",
    "    test_pred = []\n",
    "    test_gt = []\n",
    "    sense_gt = []\n",
    "    female_predic = []\n",
    "    female_gt = []\n",
    "    male_predic = []\n",
    "    male_gt = []\n",
    "    correct_00, total_00 = 0, 0\n",
    "    correct_01, total_01 = 0, 0\n",
    "    correct_10, total_10 = 0, 0\n",
    "    correct_11, total_11 = 0, 0\n",
    "    cos = nn.CosineSimilarity(dim = 0)\n",
    "    feature_a0 = []\n",
    "    feature_a1 = []\n",
    "\n",
    "    for step, (test_input, test_target, sensitive_real,img) in enumerate(tqdm(dataloader, desc=\"Zero Shot Testing\")):\n",
    "        test_target = test_target.squeeze()\n",
    "        with torch.no_grad():\n",
    "            gt = test_target.detach().cpu().numpy()\n",
    "            sen = sensitive_real.detach().cpu().numpy()\n",
    "            test_gt.extend(gt)\n",
    "            sense_gt.extend(sen)\n",
    "            test_input = test_input.to(device)\n",
    "\n",
    "            text_label_tokened\n",
    "            z = vlm.encode_image(test_input)\n",
    "            z = z/ z.norm(dim=1, keepdim=True)\n",
    "            \n",
    "            if a == True:\n",
    "                sensitive = sensitive_real\n",
    "            if a == False:\n",
    "                if partial_a == False:\n",
    "                    sensitive = inference_a(vlm, no_patch, patch,z )\n",
    "                    sensitive = torch.tensor(sensitive)\n",
    "                elif partial_a == True:\n",
    "                    sensitive = supervised_inference_a(img)\n",
    "            \n",
    "            mask_0 = sensitive == 0\n",
    "            mask_0 = mask_0.to(device)\n",
    "            z[mask_0] -= scale_0 * no_patch/ no_patch.norm(dim=1, keepdim=True)\n",
    "                \n",
    "            mask_1 = sensitive == 1\n",
    "            mask_1 = mask_1.to(device)\n",
    "            z[mask_1] -= scale_1 * patch/ patch.norm(dim=1, keepdim=True)\n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "            feature_a0.extend(z[mask_0].detach().cpu().numpy())\n",
    "            feature_a1.extend(z[mask_1].detach().cpu().numpy())\n",
    "            \n",
    "            text_embeddings = vlm.encode_text(text_label_tokened)\n",
    "            img_embeddings = z\n",
    "            norm_img_embeddings = img_embeddings / img_embeddings.norm(dim=1, keepdim=True)\n",
    "            norm_text_embeddings = text_embeddings / text_embeddings.norm(dim=1, keepdim=True)\n",
    "            cosine_similarity = torch.mm(norm_img_embeddings, norm_text_embeddings.t())\n",
    "                    \n",
    "            logits_per_image = cosine_similarity \n",
    "            probs = logits_per_image.softmax(dim=1)\n",
    "            _, predic = torch.max(probs.data, 1)\n",
    "            predic = predic.detach().cpu()\n",
    "            test_pred.extend(predic.numpy())\n",
    "            label = test_target.squeeze().detach().cpu()\n",
    "            mask_00 = ((label == 0) & (sensitive_real == 0))\n",
    "            mask_01 = ((label == 0) & (sensitive_real == 1))\n",
    "            mask_10 = ((label == 1) & (sensitive_real == 0))\n",
    "            mask_11 = ((label == 1) & (sensitive_real == 1))\n",
    "\n",
    "\n",
    "            correct_00 += (predic[mask_00] == label[mask_00]).float().sum().item()\n",
    "            total_00 += mask_00.float().sum().item()\n",
    "\n",
    "            correct_01 += (predic[mask_01] == label[mask_01]).float().sum().item()\n",
    "            total_01 += mask_01.float().sum().item()\n",
    "\n",
    "            correct_10 += (predic[mask_10] == label[mask_10]).float().sum().item()\n",
    "            total_10 += mask_10.float().sum().item()\n",
    "\n",
    "            correct_11 += (predic[mask_11] == label[mask_11]).float().sum().item()\n",
    "            total_11 += mask_11.float().sum().item() \n",
    "    acc_00 = correct_00 / total_00\n",
    "    acc_01 = correct_01 / total_01\n",
    "    acc_10 = correct_10 / total_10\n",
    "\n",
    "    print(f'Accuracy for y=0, s=0: {acc_00}')\n",
    "    print(f'Accuracy for y=0, s=1: {acc_01}')\n",
    "    print(f'Accuracy for y=1, s=0: {acc_10}')\n",
    "    acc = accuracy_score(test_gt, test_pred)\n",
    "    print('acc', accuracy_score(test_gt, test_pred))\n",
    "\n",
    "a = True\n",
    "partial_a = False\n",
    "    \n",
    "model = model.to(device)\n",
    "test_epoch(model, test_data_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sean]",
   "language": "python",
   "name": "conda-env-sean-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
